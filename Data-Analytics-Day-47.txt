 Topics + Explanations (Class Style)

1. Data Lake vs Data Warehouse
=============================
Data Warehouse: A structured, schema-on-write system optimized for analytics (e.g., Snowflake, Redshift).
Data Lake: A flexible, schema-on-read system that stores raw, semi-structured, or unstructured data (e.g., AWS S3 + Spark).

Example: Customer transactions stored in a Data Lake (raw CSVs + logs), later transformed into a Data Warehouse for BI dashboards.


2. Delta Lake and Lakehouse Architecture
======================================
Delta Lake: Adds ACID transactions + schema enforcement on top of Data Lakes.
Lakehouse: Combines the flexibility of Data Lakes with the reliability of Warehouses.

Example: Netflix uses Delta Lake to manage petabytes of streaming logs with real-time query access.


3. Data Orchestration with Apache Airflow
=======================================
Orchestration means scheduling, monitoring, and managing data pipelines.
Airflow DAGs (Directed Acyclic Graphs) define workflow steps.

Example: Daily job → Extract sales data → Clean with Pandas → Load into Snowflake.


4. Streaming Data Processing (Kafka, Spark Streaming)
=================================================
Batch = historical data processing.
Streaming = real-time data handling.
Kafka → Message broker for event streams.
Spark Streaming / Flink → Frameworks to process these streams in near real time.

Example: Uber processes live ride requests + driver data with Kafka + Flink.


5. Data Quality and Lineage
===========================
Data Quality: Ensure completeness, accuracy, and timeliness. Tools: Great Expectations, dbt tests.
Data Lineage: Track where data came from, how it was transformed, and where it’s used.

Example: Regulatory audits require banks to show full lineage of financial transactions.



